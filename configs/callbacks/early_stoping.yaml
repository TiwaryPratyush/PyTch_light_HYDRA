# early_stopping.yaml

early_stopping:
  _target_: lightning.pytorch.callbacks.EarlyStopping
  monitor: ??? # quantity to be monitored, must be specified !!!
  min_delta: 0. # minimum change in the monitored quantity to qualify as an improvement
  patience: 5 # number of checks with no improvement after which training will be stopped
  verbose: False # verbosity mode
  mode: "min" # "max" means higher metric value is better, can be also "min"
  strict: True # whether to crash the training if monitor is not found in the validation metrics
  check_finite: True # when set True, stops training when the monitor becomes NaN or infinite
  stopping_threshold: null # stop training immediately once the monitored quantity reaches this threshold
  divergence_threshold: null # stop training as soon as the monitored quantity becomes worse than this threshold
  check_on_train_epoch_end: null # whether to run early stopping at the end of the training epoch
  # log_rank_zero_only: False  # this keyword argument isn't available in stable version


# _target_: pytorch_lightning.callbacks.EarlyStopping
# monitor: "val/acc"     # Metric to monitor
# patience: 100          # Number of epochs to wait before stopping if no improvement
# mode: "max"            # "max" because we want to maximize validation accuracy
# #verbose: True          # Optional: Display early stopping logs
# #min_delta: 0.0         # Minimum change to qualify as an improvement
